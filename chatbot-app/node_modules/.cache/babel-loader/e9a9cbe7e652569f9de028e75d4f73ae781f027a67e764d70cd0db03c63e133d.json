{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useCallback, useRef } from 'react';\nimport { generateGemini2FlashResponse, generateGeminiVisionResponse } from '../services/geminiService';\nimport { useGemini } from '../context/GeminiContext';\n// Character typing speed in milliseconds\nconst TYPING_SPEED = 2; // Even faster typing speed for smoother animation\nconst CHUNK_SIZE_LARGE = 8; // Process more characters at once for very long messages\nconst CHUNK_SIZE_MEDIUM = 5; // Process more characters at once for medium messages\nconst CHUNK_SIZE_SMALL = 2; // Process more characters at once for short messages\n\nexport const useChat = () => {\n  _s();\n  const [messages, setMessages] = useState([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [isTyping, setIsTyping] = useState(false);\n  const [error, setError] = useState(null);\n  const {\n    selectedModel\n  } = useGemini();\n  const messageQueue = useRef(null);\n  const currentMessageRef = useRef(null);\n\n  // Function to simulate typing animation\n  const typeMessage = useCallback(fullResponse => {\n    // Create an AI message with empty content initially\n    const aiMessageId = Date.now().toString();\n    const aiMessage = {\n      id: aiMessageId,\n      content: '',\n      // Start with empty content\n      isUser: false,\n      timestamp: new Date()\n    };\n\n    // Add the empty AI message to the messages array\n    setMessages(prev => [...prev, aiMessage]);\n\n    // Set typing state to true to show typing indicator while generating the response\n    setIsTyping(true);\n    currentMessageRef.current = {\n      id: aiMessageId,\n      content: ''\n    };\n    let index = 0;\n    const responseLength = fullResponse.length;\n\n    // Function to add characters in chunks for smoother appearance\n    const typeCharacter = () => {\n      if (index < responseLength) {\n        // Get the next chunk of characters - process more characters at once for longer messages\n        const chunkSize = responseLength > 1000 ? CHUNK_SIZE_LARGE : responseLength > 500 ? CHUNK_SIZE_MEDIUM : CHUNK_SIZE_SMALL;\n        const endIndex = Math.min(index + chunkSize, responseLength);\n\n        // Get the next chunk of characters\n        const nextChunk = fullResponse.substring(index, endIndex);\n        const lastChar = nextChunk[nextChunk.length - 1];\n        index = endIndex;\n\n        // Update the message content with the next chunk\n        currentMessageRef.current = {\n          id: aiMessageId,\n          content: fullResponse.substring(0, index)\n        };\n\n        // Update the message in the messages array with requestAnimationFrame for smoother rendering\n        requestAnimationFrame(() => {\n          if (currentMessageRef.current) {\n            setMessages(prev => prev.map(msg => {\n              var _currentMessageRef$cu;\n              return msg.id === aiMessageId ? {\n                ...msg,\n                content: ((_currentMessageRef$cu = currentMessageRef.current) === null || _currentMessageRef$cu === void 0 ? void 0 : _currentMessageRef$cu.content) || ''\n              } : msg;\n            }));\n          }\n        });\n\n        // Adjust typing speed based on character and chunk position\n        // Slow down at punctuation but keep overall speed faster\n        const isPunctuationChar = isPunctuation(lastChar);\n        const isNewLine = lastChar === '\\n';\n        const delay = isNewLine ? TYPING_SPEED * 5 : isPunctuationChar ? TYPING_SPEED * 2 : TYPING_SPEED;\n\n        // Schedule the next character with requestAnimationFrame for smoother animation\n        setTimeout(() => {\n          requestAnimationFrame(typeCharacter);\n        }, delay);\n      } else {\n        // Typing complete\n        setIsTyping(false);\n        currentMessageRef.current = null;\n\n        // Check if there's a queued message to process next\n        if (messageQueue.current) {\n          const queuedMessage = messageQueue.current;\n          messageQueue.current = null;\n          typeMessage(queuedMessage);\n        }\n      }\n    };\n\n    // Start typing after a shorter delay\n    setTimeout(typeCharacter, 200);\n  }, []);\n\n  // Helper function to check if character is punctuation\n  const isPunctuation = char => {\n    return ['.', ',', '!', '?', ';', ':'].includes(char);\n  };\n  const generateResponse = useCallback(async userMessage => {\n    setIsLoading(true);\n    setError(null);\n    try {\n      // Use the appropriate model based on selection\n      let response;\n      if (selectedModel === 'gemini-2.0-flash') {\n        response = await generateGemini2FlashResponse(userMessage);\n      } else {\n        // Default to 1.5 Flash\n        response = await generateGeminiVisionResponse(userMessage);\n      }\n      if (!response) {\n        throw new Error('No response received from the AI');\n      }\n      return response;\n    } catch (err) {\n      console.error('Error generating response:', err);\n      setError(err.message || 'Failed to generate response');\n      return null;\n    } finally {\n      setIsLoading(false);\n    }\n  }, [selectedModel]);\n  const sendMessage = useCallback(async content => {\n    if (!content.trim()) return;\n\n    // Clear any existing errors\n    setError(null);\n\n    // Add user message\n    const userMessage = {\n      id: Date.now().toString(),\n      content: content.trim(),\n      isUser: true,\n      timestamp: new Date()\n    };\n    setMessages(prev => [...prev, userMessage]);\n\n    // Generate AI response\n    const response = await generateResponse(content);\n    if (response) {\n      // If already typing, queue this message\n      if (isTyping) {\n        messageQueue.current = response;\n      } else {\n        // Start typing animation for this message\n        typeMessage(response);\n      }\n    }\n  }, [generateResponse, isTyping, typeMessage]);\n  const clearMessages = useCallback(() => {\n    setMessages([]);\n    setError(null);\n    messageQueue.current = null;\n    currentMessageRef.current = null;\n  }, []);\n  return {\n    messages,\n    isLoading,\n    isTyping,\n    error,\n    sendMessage,\n    selectedModel,\n    clearMessages\n  };\n};\n_s(useChat, \"BbnrBV2tuHRHHr82XAwhOn4s1QQ=\", false, function () {\n  return [useGemini];\n});\nexport default useChat;","map":{"version":3,"names":["useState","useCallback","useRef","generateGemini2FlashResponse","generateGeminiVisionResponse","useGemini","TYPING_SPEED","CHUNK_SIZE_LARGE","CHUNK_SIZE_MEDIUM","CHUNK_SIZE_SMALL","useChat","_s","messages","setMessages","isLoading","setIsLoading","isTyping","setIsTyping","error","setError","selectedModel","messageQueue","currentMessageRef","typeMessage","fullResponse","aiMessageId","Date","now","toString","aiMessage","id","content","isUser","timestamp","prev","current","index","responseLength","length","typeCharacter","chunkSize","endIndex","Math","min","nextChunk","substring","lastChar","requestAnimationFrame","map","msg","_currentMessageRef$cu","isPunctuationChar","isPunctuation","isNewLine","delay","setTimeout","queuedMessage","char","includes","generateResponse","userMessage","response","Error","err","console","message","sendMessage","trim","clearMessages"],"sources":["C:/Users/alamk/OneDrive/Desktop/Chatbot/chatbot-app/src/hooks/useChat.ts"],"sourcesContent":["import { useState, useCallback, useRef } from 'react';\nimport { generateGemini2FlashResponse, generateGeminiVisionResponse } from '../services/geminiService';\nimport { useGemini } from '../context/GeminiContext';\n\ninterface Message {\n  id: string;\n  content: string;\n  isUser: boolean;\n  timestamp: Date;\n}\n\n// Character typing speed in milliseconds\nconst TYPING_SPEED = 2; // Even faster typing speed for smoother animation\nconst CHUNK_SIZE_LARGE = 8; // Process more characters at once for very long messages\nconst CHUNK_SIZE_MEDIUM = 5; // Process more characters at once for medium messages\nconst CHUNK_SIZE_SMALL = 2; // Process more characters at once for short messages\n\nexport const useChat = () => {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [isTyping, setIsTyping] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n  const { selectedModel } = useGemini();\n  const messageQueue = useRef<string | null>(null);\n  const currentMessageRef = useRef<{id: string, content: string} | null>(null);\n\n  // Function to simulate typing animation\n  const typeMessage = useCallback((fullResponse: string) => {\n    // Create an AI message with empty content initially\n    const aiMessageId = Date.now().toString();\n    const aiMessage: Message = {\n      id: aiMessageId,\n      content: '', // Start with empty content\n      isUser: false,\n      timestamp: new Date()\n    };\n    \n    // Add the empty AI message to the messages array\n    setMessages(prev => [...prev, aiMessage]);\n    \n    // Set typing state to true to show typing indicator while generating the response\n    setIsTyping(true);\n    currentMessageRef.current = { id: aiMessageId, content: '' };\n    \n    let index = 0;\n    const responseLength = fullResponse.length;\n    \n    // Function to add characters in chunks for smoother appearance\n    const typeCharacter = () => {\n      if (index < responseLength) {\n        // Get the next chunk of characters - process more characters at once for longer messages\n        const chunkSize = responseLength > 1000 ? CHUNK_SIZE_LARGE : \n                         responseLength > 500 ? CHUNK_SIZE_MEDIUM : CHUNK_SIZE_SMALL;\n        const endIndex = Math.min(index + chunkSize, responseLength);\n        \n        // Get the next chunk of characters\n        const nextChunk = fullResponse.substring(index, endIndex);\n        const lastChar = nextChunk[nextChunk.length - 1];\n        index = endIndex;\n        \n        // Update the message content with the next chunk\n        currentMessageRef.current = {\n          id: aiMessageId,\n          content: fullResponse.substring(0, index)\n        };\n        \n        // Update the message in the messages array with requestAnimationFrame for smoother rendering\n        requestAnimationFrame(() => {\n          if (currentMessageRef.current) {\n            setMessages(prev => \n              prev.map(msg => \n                msg.id === aiMessageId \n                  ? { ...msg, content: currentMessageRef.current?.content || '' } \n                  : msg\n              )\n            );\n          }\n        });\n        \n        // Adjust typing speed based on character and chunk position\n        // Slow down at punctuation but keep overall speed faster\n        const isPunctuationChar = isPunctuation(lastChar);\n        const isNewLine = lastChar === '\\n';\n        const delay = isNewLine ? TYPING_SPEED * 5 : \n                     isPunctuationChar ? TYPING_SPEED * 2 : \n                     TYPING_SPEED;\n        \n        // Schedule the next character with requestAnimationFrame for smoother animation\n        setTimeout(() => {\n          requestAnimationFrame(typeCharacter);\n        }, delay);\n      } else {\n        // Typing complete\n        setIsTyping(false);\n        currentMessageRef.current = null;\n        \n        // Check if there's a queued message to process next\n        if (messageQueue.current) {\n          const queuedMessage = messageQueue.current;\n          messageQueue.current = null;\n          typeMessage(queuedMessage);\n        }\n      }\n    };\n    \n    // Start typing after a shorter delay\n    setTimeout(typeCharacter, 200);\n  }, []);\n  \n  // Helper function to check if character is punctuation\n  const isPunctuation = (char: string): boolean => {\n    return ['.', ',', '!', '?', ';', ':'].includes(char);\n  };\n\n  const generateResponse = useCallback(async (userMessage: string) => {\n    setIsLoading(true);\n    setError(null);\n\n    try {\n      // Use the appropriate model based on selection\n      let response: string;\n      \n      if (selectedModel === 'gemini-2.0-flash') {\n        response = await generateGemini2FlashResponse(userMessage);\n      } else {\n        // Default to 1.5 Flash\n        response = await generateGeminiVisionResponse(userMessage);\n      }\n\n      if (!response) {\n        throw new Error('No response received from the AI');\n      }\n\n      return response;\n    } catch (err: any) {\n      console.error('Error generating response:', err);\n      setError(err.message || 'Failed to generate response');\n      return null;\n    } finally {\n      setIsLoading(false);\n    }\n  }, [selectedModel]);\n\n  const sendMessage = useCallback(async (content: string) => {\n    if (!content.trim()) return;\n\n    // Clear any existing errors\n    setError(null);\n\n    // Add user message\n    const userMessage: Message = {\n      id: Date.now().toString(),\n      content: content.trim(),\n      isUser: true,\n      timestamp: new Date()\n    };\n    setMessages(prev => [...prev, userMessage]);\n\n    // Generate AI response\n    const response = await generateResponse(content);\n    \n    if (response) {\n      // If already typing, queue this message\n      if (isTyping) {\n        messageQueue.current = response;\n      } else {\n        // Start typing animation for this message\n        typeMessage(response);\n      }\n    }\n  }, [generateResponse, isTyping, typeMessage]);\n\n  const clearMessages = useCallback(() => {\n    setMessages([]);\n    setError(null);\n    messageQueue.current = null;\n    currentMessageRef.current = null;\n  }, []);\n\n  return {\n    messages,\n    isLoading,\n    isTyping,\n    error,\n    sendMessage,\n    selectedModel,\n    clearMessages\n  };\n};\n\nexport default useChat;"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,WAAW,EAAEC,MAAM,QAAQ,OAAO;AACrD,SAASC,4BAA4B,EAAEC,4BAA4B,QAAQ,2BAA2B;AACtG,SAASC,SAAS,QAAQ,0BAA0B;AASpD;AACA,MAAMC,YAAY,GAAG,CAAC,CAAC,CAAC;AACxB,MAAMC,gBAAgB,GAAG,CAAC,CAAC,CAAC;AAC5B,MAAMC,iBAAiB,GAAG,CAAC,CAAC,CAAC;AAC7B,MAAMC,gBAAgB,GAAG,CAAC,CAAC,CAAC;;AAE5B,OAAO,MAAMC,OAAO,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGb,QAAQ,CAAY,EAAE,CAAC;EACvD,MAAM,CAACc,SAAS,EAAEC,YAAY,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACgB,QAAQ,EAAEC,WAAW,CAAC,GAAGjB,QAAQ,CAAC,KAAK,CAAC;EAC/C,MAAM,CAACkB,KAAK,EAAEC,QAAQ,CAAC,GAAGnB,QAAQ,CAAgB,IAAI,CAAC;EACvD,MAAM;IAAEoB;EAAc,CAAC,GAAGf,SAAS,CAAC,CAAC;EACrC,MAAMgB,YAAY,GAAGnB,MAAM,CAAgB,IAAI,CAAC;EAChD,MAAMoB,iBAAiB,GAAGpB,MAAM,CAAuC,IAAI,CAAC;;EAE5E;EACA,MAAMqB,WAAW,GAAGtB,WAAW,CAAEuB,YAAoB,IAAK;IACxD;IACA,MAAMC,WAAW,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,CAACC,QAAQ,CAAC,CAAC;IACzC,MAAMC,SAAkB,GAAG;MACzBC,EAAE,EAAEL,WAAW;MACfM,OAAO,EAAE,EAAE;MAAE;MACbC,MAAM,EAAE,KAAK;MACbC,SAAS,EAAE,IAAIP,IAAI,CAAC;IACtB,CAAC;;IAED;IACAb,WAAW,CAACqB,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAEL,SAAS,CAAC,CAAC;;IAEzC;IACAZ,WAAW,CAAC,IAAI,CAAC;IACjBK,iBAAiB,CAACa,OAAO,GAAG;MAAEL,EAAE,EAAEL,WAAW;MAAEM,OAAO,EAAE;IAAG,CAAC;IAE5D,IAAIK,KAAK,GAAG,CAAC;IACb,MAAMC,cAAc,GAAGb,YAAY,CAACc,MAAM;;IAE1C;IACA,MAAMC,aAAa,GAAGA,CAAA,KAAM;MAC1B,IAAIH,KAAK,GAAGC,cAAc,EAAE;QAC1B;QACA,MAAMG,SAAS,GAAGH,cAAc,GAAG,IAAI,GAAG9B,gBAAgB,GACzC8B,cAAc,GAAG,GAAG,GAAG7B,iBAAiB,GAAGC,gBAAgB;QAC5E,MAAMgC,QAAQ,GAAGC,IAAI,CAACC,GAAG,CAACP,KAAK,GAAGI,SAAS,EAAEH,cAAc,CAAC;;QAE5D;QACA,MAAMO,SAAS,GAAGpB,YAAY,CAACqB,SAAS,CAACT,KAAK,EAAEK,QAAQ,CAAC;QACzD,MAAMK,QAAQ,GAAGF,SAAS,CAACA,SAAS,CAACN,MAAM,GAAG,CAAC,CAAC;QAChDF,KAAK,GAAGK,QAAQ;;QAEhB;QACAnB,iBAAiB,CAACa,OAAO,GAAG;UAC1BL,EAAE,EAAEL,WAAW;UACfM,OAAO,EAAEP,YAAY,CAACqB,SAAS,CAAC,CAAC,EAAET,KAAK;QAC1C,CAAC;;QAED;QACAW,qBAAqB,CAAC,MAAM;UAC1B,IAAIzB,iBAAiB,CAACa,OAAO,EAAE;YAC7BtB,WAAW,CAACqB,IAAI,IACdA,IAAI,CAACc,GAAG,CAACC,GAAG;cAAA,IAAAC,qBAAA;cAAA,OACVD,GAAG,CAACnB,EAAE,KAAKL,WAAW,GAClB;gBAAE,GAAGwB,GAAG;gBAAElB,OAAO,EAAE,EAAAmB,qBAAA,GAAA5B,iBAAiB,CAACa,OAAO,cAAAe,qBAAA,uBAAzBA,qBAAA,CAA2BnB,OAAO,KAAI;cAAG,CAAC,GAC7DkB,GAAG;YAAA,CACT,CACF,CAAC;UACH;QACF,CAAC,CAAC;;QAEF;QACA;QACA,MAAME,iBAAiB,GAAGC,aAAa,CAACN,QAAQ,CAAC;QACjD,MAAMO,SAAS,GAAGP,QAAQ,KAAK,IAAI;QACnC,MAAMQ,KAAK,GAAGD,SAAS,GAAG/C,YAAY,GAAG,CAAC,GAC7B6C,iBAAiB,GAAG7C,YAAY,GAAG,CAAC,GACpCA,YAAY;;QAEzB;QACAiD,UAAU,CAAC,MAAM;UACfR,qBAAqB,CAACR,aAAa,CAAC;QACtC,CAAC,EAAEe,KAAK,CAAC;MACX,CAAC,MAAM;QACL;QACArC,WAAW,CAAC,KAAK,CAAC;QAClBK,iBAAiB,CAACa,OAAO,GAAG,IAAI;;QAEhC;QACA,IAAId,YAAY,CAACc,OAAO,EAAE;UACxB,MAAMqB,aAAa,GAAGnC,YAAY,CAACc,OAAO;UAC1Cd,YAAY,CAACc,OAAO,GAAG,IAAI;UAC3BZ,WAAW,CAACiC,aAAa,CAAC;QAC5B;MACF;IACF,CAAC;;IAED;IACAD,UAAU,CAAChB,aAAa,EAAE,GAAG,CAAC;EAChC,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMa,aAAa,GAAIK,IAAY,IAAc;IAC/C,OAAO,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAACC,QAAQ,CAACD,IAAI,CAAC;EACtD,CAAC;EAED,MAAME,gBAAgB,GAAG1D,WAAW,CAAC,MAAO2D,WAAmB,IAAK;IAClE7C,YAAY,CAAC,IAAI,CAAC;IAClBI,QAAQ,CAAC,IAAI,CAAC;IAEd,IAAI;MACF;MACA,IAAI0C,QAAgB;MAEpB,IAAIzC,aAAa,KAAK,kBAAkB,EAAE;QACxCyC,QAAQ,GAAG,MAAM1D,4BAA4B,CAACyD,WAAW,CAAC;MAC5D,CAAC,MAAM;QACL;QACAC,QAAQ,GAAG,MAAMzD,4BAA4B,CAACwD,WAAW,CAAC;MAC5D;MAEA,IAAI,CAACC,QAAQ,EAAE;QACb,MAAM,IAAIC,KAAK,CAAC,kCAAkC,CAAC;MACrD;MAEA,OAAOD,QAAQ;IACjB,CAAC,CAAC,OAAOE,GAAQ,EAAE;MACjBC,OAAO,CAAC9C,KAAK,CAAC,4BAA4B,EAAE6C,GAAG,CAAC;MAChD5C,QAAQ,CAAC4C,GAAG,CAACE,OAAO,IAAI,6BAA6B,CAAC;MACtD,OAAO,IAAI;IACb,CAAC,SAAS;MACRlD,YAAY,CAAC,KAAK,CAAC;IACrB;EACF,CAAC,EAAE,CAACK,aAAa,CAAC,CAAC;EAEnB,MAAM8C,WAAW,GAAGjE,WAAW,CAAC,MAAO8B,OAAe,IAAK;IACzD,IAAI,CAACA,OAAO,CAACoC,IAAI,CAAC,CAAC,EAAE;;IAErB;IACAhD,QAAQ,CAAC,IAAI,CAAC;;IAEd;IACA,MAAMyC,WAAoB,GAAG;MAC3B9B,EAAE,EAAEJ,IAAI,CAACC,GAAG,CAAC,CAAC,CAACC,QAAQ,CAAC,CAAC;MACzBG,OAAO,EAAEA,OAAO,CAACoC,IAAI,CAAC,CAAC;MACvBnC,MAAM,EAAE,IAAI;MACZC,SAAS,EAAE,IAAIP,IAAI,CAAC;IACtB,CAAC;IACDb,WAAW,CAACqB,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAE0B,WAAW,CAAC,CAAC;;IAE3C;IACA,MAAMC,QAAQ,GAAG,MAAMF,gBAAgB,CAAC5B,OAAO,CAAC;IAEhD,IAAI8B,QAAQ,EAAE;MACZ;MACA,IAAI7C,QAAQ,EAAE;QACZK,YAAY,CAACc,OAAO,GAAG0B,QAAQ;MACjC,CAAC,MAAM;QACL;QACAtC,WAAW,CAACsC,QAAQ,CAAC;MACvB;IACF;EACF,CAAC,EAAE,CAACF,gBAAgB,EAAE3C,QAAQ,EAAEO,WAAW,CAAC,CAAC;EAE7C,MAAM6C,aAAa,GAAGnE,WAAW,CAAC,MAAM;IACtCY,WAAW,CAAC,EAAE,CAAC;IACfM,QAAQ,CAAC,IAAI,CAAC;IACdE,YAAY,CAACc,OAAO,GAAG,IAAI;IAC3Bb,iBAAiB,CAACa,OAAO,GAAG,IAAI;EAClC,CAAC,EAAE,EAAE,CAAC;EAEN,OAAO;IACLvB,QAAQ;IACRE,SAAS;IACTE,QAAQ;IACRE,KAAK;IACLgD,WAAW;IACX9C,aAAa;IACbgD;EACF,CAAC;AACH,CAAC;AAACzD,EAAA,CA3KWD,OAAO;EAAA,QAKQL,SAAS;AAAA;AAwKrC,eAAeK,OAAO","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}