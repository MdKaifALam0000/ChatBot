{"ast":null,"code":"var _s = $RefreshSig$();\nimport { useState, useCallback, useRef } from 'react';\nimport { generateGemini2FlashResponse, generateGeminiVisionResponse } from '../services/geminiService';\nimport { useGemini } from '../context/GeminiContext';\n// Character typing speed in milliseconds\nconst TYPING_SPEED = 2; // Even faster typing speed for smoother animation\nconst CHUNK_SIZE_LARGE = 8; // Process more characters at once for very long messages\nconst CHUNK_SIZE_MEDIUM = 5; // Process more characters at once for medium messages\nconst CHUNK_SIZE_SMALL = 2; // Process more characters at once for short messages\n\nexport const useChat = () => {\n  _s();\n  const [messages, setMessages] = useState([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [isTyping, setIsTyping] = useState(false);\n  const [error, setError] = useState(null);\n  const {\n    selectedModel\n  } = useGemini();\n  const messageQueue = useRef(null);\n  const currentMessageRef = useRef(null);\n\n  // Function to simulate typing animation\n  const typeMessage = useCallback(fullResponse => {\n    if (!fullResponse) {\n      console.warn('Empty response received in typeMessage');\n      return;\n    }\n\n    // If already typing, queue this message\n    if (isTyping) {\n      messageQueue.current = fullResponse;\n      return;\n    }\n    setIsTyping(true);\n\n    // Create a new message for the AI response\n    const aiMessageId = Date.now().toString();\n    setMessages(prev => [...prev, {\n      id: aiMessageId,\n      content: '',\n      isUser: false,\n      timestamp: new Date()\n    }]);\n\n    // Keep track of the current message being typed\n    currentMessageRef.current = {\n      id: aiMessageId,\n      content: ''\n    };\n\n    // Set up the typing animation\n    let index = 0;\n    const responseLength = fullResponse.length;\n\n    // Function to add characters in chunks for smoother appearance\n    const typeCharacter = () => {\n      if (index < responseLength) {\n        // Get the next chunk of characters - process more characters at once for longer messages\n        const chunkSize = responseLength > 1000 ? CHUNK_SIZE_LARGE : responseLength > 500 ? CHUNK_SIZE_MEDIUM : CHUNK_SIZE_SMALL;\n        const endIndex = Math.min(index + chunkSize, responseLength);\n\n        // Get the next chunk of characters\n        const nextChunk = fullResponse.substring(index, endIndex);\n        const lastChar = nextChunk[nextChunk.length - 1];\n        index = endIndex;\n\n        // Update the message content with the next chunk\n        currentMessageRef.current = {\n          id: aiMessageId,\n          content: fullResponse.substring(0, index)\n        };\n\n        // Update the message in the messages array with requestAnimationFrame for smoother rendering\n        requestAnimationFrame(() => {\n          if (currentMessageRef.current) {\n            setMessages(prev => prev.map(msg => {\n              var _currentMessageRef$cu;\n              return msg.id === aiMessageId ? {\n                ...msg,\n                content: ((_currentMessageRef$cu = currentMessageRef.current) === null || _currentMessageRef$cu === void 0 ? void 0 : _currentMessageRef$cu.content) || ''\n              } : msg;\n            }));\n          }\n        });\n\n        // Adjust typing speed based on character and chunk position\n        // Slow down at punctuation but keep overall speed faster\n        const isPunctuationChar = isPunctuation(lastChar);\n        const isNewLine = lastChar === '\\n';\n        const delay = isNewLine ? TYPING_SPEED * 5 : isPunctuationChar ? TYPING_SPEED * 2 : TYPING_SPEED;\n\n        // Schedule the next character with requestAnimationFrame for smoother animation\n        setTimeout(() => {\n          requestAnimationFrame(typeCharacter);\n        }, delay);\n      } else {\n        // Typing complete\n        setIsTyping(false);\n        currentMessageRef.current = null;\n\n        // Check if there's a queued message to process next\n        if (messageQueue.current) {\n          const queuedMessage = messageQueue.current;\n          messageQueue.current = null;\n          typeMessage(queuedMessage);\n        }\n      }\n    };\n\n    // Start typing after a shorter delay\n    setTimeout(typeCharacter, 200);\n  }, []);\n\n  // Helper function to check if character is punctuation\n  const isPunctuation = char => {\n    return ['.', ',', '!', '?', ';', ':'].includes(char);\n  };\n  const generateResponse = useCallback(async userMessage => {\n    try {\n      setIsLoading(true);\n      setError(null);\n\n      // Add the user message to the messages array\n      const userMessageObj = {\n        id: Date.now().toString(),\n        content: userMessage,\n        isUser: true,\n        timestamp: new Date()\n      };\n      setMessages(prev => [...prev, userMessageObj]);\n\n      // Generate a response from the AI\n      let response;\n      try {\n        if (selectedModel === 'gemini-vision') {\n          response = await generateGeminiVisionResponse(userMessage);\n        } else {\n          response = await generateGemini2FlashResponse(userMessage);\n        }\n\n        // Ensure we have a valid response\n        if (!response || typeof response !== 'string') {\n          throw new Error('Invalid response format');\n        }\n\n        // Type out the response character by character\n        typeMessage(response);\n      } catch (apiError) {\n        console.error('API Error:', apiError);\n        setError('Failed to connect to Gemini. Please check your API key and try again.');\n      }\n    } catch (err) {\n      console.error('Error generating response:', err);\n      setError('Failed to generate a response. Please try again.');\n    } finally {\n      setIsLoading(false);\n    }\n  }, [selectedModel, typeMessage]);\n  const sendMessage = useCallback(async content => {\n    if (!content.trim()) return;\n\n    // Clear any existing errors\n    setError(null);\n\n    // Add user message\n    const userMessage = {\n      id: Date.now().toString(),\n      content: content.trim(),\n      isUser: true,\n      timestamp: new Date()\n    };\n    setMessages(prev => [...prev, userMessage]);\n\n    // Generate AI response\n    const response = await generateResponse(content);\n    if (response) {\n      // If already typing, queue this message\n      if (isTyping) {\n        messageQueue.current = response;\n      } else {\n        // Start typing animation for this message\n        typeMessage(response);\n      }\n    }\n  }, [generateResponse, isTyping, typeMessage]);\n  const clearMessages = useCallback(() => {\n    setMessages([]);\n    setError(null);\n    messageQueue.current = null;\n    currentMessageRef.current = null;\n  }, []);\n  return {\n    messages,\n    isLoading,\n    isTyping,\n    error,\n    sendMessage,\n    selectedModel,\n    clearMessages\n  };\n};\n_s(useChat, \"BbnrBV2tuHRHHr82XAwhOn4s1QQ=\", false, function () {\n  return [useGemini];\n});\nexport default useChat;","map":{"version":3,"names":["useState","useCallback","useRef","generateGemini2FlashResponse","generateGeminiVisionResponse","useGemini","TYPING_SPEED","CHUNK_SIZE_LARGE","CHUNK_SIZE_MEDIUM","CHUNK_SIZE_SMALL","useChat","_s","messages","setMessages","isLoading","setIsLoading","isTyping","setIsTyping","error","setError","selectedModel","messageQueue","currentMessageRef","typeMessage","fullResponse","console","warn","current","aiMessageId","Date","now","toString","prev","id","content","isUser","timestamp","index","responseLength","length","typeCharacter","chunkSize","endIndex","Math","min","nextChunk","substring","lastChar","requestAnimationFrame","map","msg","_currentMessageRef$cu","isPunctuationChar","isPunctuation","isNewLine","delay","setTimeout","queuedMessage","char","includes","generateResponse","userMessage","userMessageObj","response","Error","apiError","err","sendMessage","trim","clearMessages"],"sources":["C:/Users/alamk/OneDrive/Desktop/Chatbot/chatbot-app/src/hooks/useChat.ts"],"sourcesContent":["import { useState, useCallback, useRef } from 'react';\nimport { generateGemini2FlashResponse, generateGeminiVisionResponse } from '../services/geminiService';\nimport { useGemini } from '../context/GeminiContext';\n\ninterface Message {\n  id: string;\n  content: string;\n  isUser: boolean;\n  timestamp: Date;\n}\n\n// Character typing speed in milliseconds\nconst TYPING_SPEED = 2; // Even faster typing speed for smoother animation\nconst CHUNK_SIZE_LARGE = 8; // Process more characters at once for very long messages\nconst CHUNK_SIZE_MEDIUM = 5; // Process more characters at once for medium messages\nconst CHUNK_SIZE_SMALL = 2; // Process more characters at once for short messages\n\nexport const useChat = () => {\n  const [messages, setMessages] = useState<Message[]>([]);\n  const [isLoading, setIsLoading] = useState(false);\n  const [isTyping, setIsTyping] = useState(false);\n  const [error, setError] = useState<string | null>(null);\n  const { selectedModel } = useGemini();\n  const messageQueue = useRef<string | null>(null);\n  const currentMessageRef = useRef<{id: string, content: string} | null>(null);\n\n  // Function to simulate typing animation\n  const typeMessage = useCallback((fullResponse: string) => {\n    if (!fullResponse) {\n      console.warn('Empty response received in typeMessage');\n      return;\n    }\n    \n    // If already typing, queue this message\n    if (isTyping) {\n      messageQueue.current = fullResponse;\n      return;\n    }\n    \n    setIsTyping(true);\n    \n    // Create a new message for the AI response\n    const aiMessageId = Date.now().toString();\n    setMessages(prev => [...prev, { id: aiMessageId, content: '', isUser: false, timestamp: new Date() }]);\n    \n    // Keep track of the current message being typed\n    currentMessageRef.current = { id: aiMessageId, content: '' };\n    \n    // Set up the typing animation\n    let index = 0;\n    const responseLength = fullResponse.length;\n    \n    // Function to add characters in chunks for smoother appearance\n    const typeCharacter = () => {\n      if (index < responseLength) {\n        // Get the next chunk of characters - process more characters at once for longer messages\n        const chunkSize = responseLength > 1000 ? CHUNK_SIZE_LARGE : \n                         responseLength > 500 ? CHUNK_SIZE_MEDIUM : CHUNK_SIZE_SMALL;\n        const endIndex = Math.min(index + chunkSize, responseLength);\n        \n        // Get the next chunk of characters\n        const nextChunk = fullResponse.substring(index, endIndex);\n        const lastChar = nextChunk[nextChunk.length - 1];\n        index = endIndex;\n        \n        // Update the message content with the next chunk\n        currentMessageRef.current = {\n          id: aiMessageId,\n          content: fullResponse.substring(0, index)\n        };\n        \n        // Update the message in the messages array with requestAnimationFrame for smoother rendering\n        requestAnimationFrame(() => {\n          if (currentMessageRef.current) {\n            setMessages(prev => \n              prev.map(msg => \n                msg.id === aiMessageId \n                  ? { ...msg, content: currentMessageRef.current?.content || '' } \n                  : msg\n              )\n            );\n          }\n        });\n        \n        // Adjust typing speed based on character and chunk position\n        // Slow down at punctuation but keep overall speed faster\n        const isPunctuationChar = isPunctuation(lastChar);\n        const isNewLine = lastChar === '\\n';\n        const delay = isNewLine ? TYPING_SPEED * 5 : \n                     isPunctuationChar ? TYPING_SPEED * 2 : \n                     TYPING_SPEED;\n        \n        // Schedule the next character with requestAnimationFrame for smoother animation\n        setTimeout(() => {\n          requestAnimationFrame(typeCharacter);\n        }, delay);\n      } else {\n        // Typing complete\n        setIsTyping(false);\n        currentMessageRef.current = null;\n        \n        // Check if there's a queued message to process next\n        if (messageQueue.current) {\n          const queuedMessage = messageQueue.current;\n          messageQueue.current = null;\n          typeMessage(queuedMessage);\n        }\n      }\n    };\n    \n    // Start typing after a shorter delay\n    setTimeout(typeCharacter, 200);\n  }, []);\n  \n  // Helper function to check if character is punctuation\n  const isPunctuation = (char: string): boolean => {\n    return ['.', ',', '!', '?', ';', ':'].includes(char);\n  };\n\n  const generateResponse = useCallback(async (userMessage: string) => {\n    try {\n      setIsLoading(true);\n      setError(null);\n      \n      // Add the user message to the messages array\n      const userMessageObj: Message = {\n        id: Date.now().toString(),\n        content: userMessage,\n        isUser: true,\n        timestamp: new Date()\n      };\n      \n      setMessages(prev => [...prev, userMessageObj]);\n      \n      // Generate a response from the AI\n      let response;\n      \n      try {\n        if (selectedModel === 'gemini-vision') {\n          response = await generateGeminiVisionResponse(userMessage);\n        } else {\n          response = await generateGemini2FlashResponse(userMessage);\n        }\n        \n        // Ensure we have a valid response\n        if (!response || typeof response !== 'string') {\n          throw new Error('Invalid response format');\n        }\n        \n        // Type out the response character by character\n        typeMessage(response);\n      } catch (apiError) {\n        console.error('API Error:', apiError);\n        setError('Failed to connect to Gemini. Please check your API key and try again.');\n      }\n      \n    } catch (err) {\n      console.error('Error generating response:', err);\n      setError('Failed to generate a response. Please try again.');\n    } finally {\n      setIsLoading(false);\n    }\n  }, [selectedModel, typeMessage]);\n\n  const sendMessage = useCallback(async (content: string) => {\n    if (!content.trim()) return;\n\n    // Clear any existing errors\n    setError(null);\n\n    // Add user message\n    const userMessage: Message = {\n      id: Date.now().toString(),\n      content: content.trim(),\n      isUser: true,\n      timestamp: new Date()\n    };\n    setMessages(prev => [...prev, userMessage]);\n\n    // Generate AI response\n    const response = await generateResponse(content);\n    \n    if (response) {\n      // If already typing, queue this message\n      if (isTyping) {\n        messageQueue.current = response;\n      } else {\n        // Start typing animation for this message\n        typeMessage(response);\n      }\n    }\n  }, [generateResponse, isTyping, typeMessage]);\n\n  const clearMessages = useCallback(() => {\n    setMessages([]);\n    setError(null);\n    messageQueue.current = null;\n    currentMessageRef.current = null;\n  }, []);\n\n  return {\n    messages,\n    isLoading,\n    isTyping,\n    error,\n    sendMessage,\n    selectedModel,\n    clearMessages\n  };\n};\n\nexport default useChat;"],"mappings":";AAAA,SAASA,QAAQ,EAAEC,WAAW,EAAEC,MAAM,QAAQ,OAAO;AACrD,SAASC,4BAA4B,EAAEC,4BAA4B,QAAQ,2BAA2B;AACtG,SAASC,SAAS,QAAQ,0BAA0B;AASpD;AACA,MAAMC,YAAY,GAAG,CAAC,CAAC,CAAC;AACxB,MAAMC,gBAAgB,GAAG,CAAC,CAAC,CAAC;AAC5B,MAAMC,iBAAiB,GAAG,CAAC,CAAC,CAAC;AAC7B,MAAMC,gBAAgB,GAAG,CAAC,CAAC,CAAC;;AAE5B,OAAO,MAAMC,OAAO,GAAGA,CAAA,KAAM;EAAAC,EAAA;EAC3B,MAAM,CAACC,QAAQ,EAAEC,WAAW,CAAC,GAAGb,QAAQ,CAAY,EAAE,CAAC;EACvD,MAAM,CAACc,SAAS,EAAEC,YAAY,CAAC,GAAGf,QAAQ,CAAC,KAAK,CAAC;EACjD,MAAM,CAACgB,QAAQ,EAAEC,WAAW,CAAC,GAAGjB,QAAQ,CAAC,KAAK,CAAC;EAC/C,MAAM,CAACkB,KAAK,EAAEC,QAAQ,CAAC,GAAGnB,QAAQ,CAAgB,IAAI,CAAC;EACvD,MAAM;IAAEoB;EAAc,CAAC,GAAGf,SAAS,CAAC,CAAC;EACrC,MAAMgB,YAAY,GAAGnB,MAAM,CAAgB,IAAI,CAAC;EAChD,MAAMoB,iBAAiB,GAAGpB,MAAM,CAAuC,IAAI,CAAC;;EAE5E;EACA,MAAMqB,WAAW,GAAGtB,WAAW,CAAEuB,YAAoB,IAAK;IACxD,IAAI,CAACA,YAAY,EAAE;MACjBC,OAAO,CAACC,IAAI,CAAC,wCAAwC,CAAC;MACtD;IACF;;IAEA;IACA,IAAIV,QAAQ,EAAE;MACZK,YAAY,CAACM,OAAO,GAAGH,YAAY;MACnC;IACF;IAEAP,WAAW,CAAC,IAAI,CAAC;;IAEjB;IACA,MAAMW,WAAW,GAAGC,IAAI,CAACC,GAAG,CAAC,CAAC,CAACC,QAAQ,CAAC,CAAC;IACzClB,WAAW,CAACmB,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAE;MAAEC,EAAE,EAAEL,WAAW;MAAEM,OAAO,EAAE,EAAE;MAAEC,MAAM,EAAE,KAAK;MAAEC,SAAS,EAAE,IAAIP,IAAI,CAAC;IAAE,CAAC,CAAC,CAAC;;IAEtG;IACAP,iBAAiB,CAACK,OAAO,GAAG;MAAEM,EAAE,EAAEL,WAAW;MAAEM,OAAO,EAAE;IAAG,CAAC;;IAE5D;IACA,IAAIG,KAAK,GAAG,CAAC;IACb,MAAMC,cAAc,GAAGd,YAAY,CAACe,MAAM;;IAE1C;IACA,MAAMC,aAAa,GAAGA,CAAA,KAAM;MAC1B,IAAIH,KAAK,GAAGC,cAAc,EAAE;QAC1B;QACA,MAAMG,SAAS,GAAGH,cAAc,GAAG,IAAI,GAAG/B,gBAAgB,GACzC+B,cAAc,GAAG,GAAG,GAAG9B,iBAAiB,GAAGC,gBAAgB;QAC5E,MAAMiC,QAAQ,GAAGC,IAAI,CAACC,GAAG,CAACP,KAAK,GAAGI,SAAS,EAAEH,cAAc,CAAC;;QAE5D;QACA,MAAMO,SAAS,GAAGrB,YAAY,CAACsB,SAAS,CAACT,KAAK,EAAEK,QAAQ,CAAC;QACzD,MAAMK,QAAQ,GAAGF,SAAS,CAACA,SAAS,CAACN,MAAM,GAAG,CAAC,CAAC;QAChDF,KAAK,GAAGK,QAAQ;;QAEhB;QACApB,iBAAiB,CAACK,OAAO,GAAG;UAC1BM,EAAE,EAAEL,WAAW;UACfM,OAAO,EAAEV,YAAY,CAACsB,SAAS,CAAC,CAAC,EAAET,KAAK;QAC1C,CAAC;;QAED;QACAW,qBAAqB,CAAC,MAAM;UAC1B,IAAI1B,iBAAiB,CAACK,OAAO,EAAE;YAC7Bd,WAAW,CAACmB,IAAI,IACdA,IAAI,CAACiB,GAAG,CAACC,GAAG;cAAA,IAAAC,qBAAA;cAAA,OACVD,GAAG,CAACjB,EAAE,KAAKL,WAAW,GAClB;gBAAE,GAAGsB,GAAG;gBAAEhB,OAAO,EAAE,EAAAiB,qBAAA,GAAA7B,iBAAiB,CAACK,OAAO,cAAAwB,qBAAA,uBAAzBA,qBAAA,CAA2BjB,OAAO,KAAI;cAAG,CAAC,GAC7DgB,GAAG;YAAA,CACT,CACF,CAAC;UACH;QACF,CAAC,CAAC;;QAEF;QACA;QACA,MAAME,iBAAiB,GAAGC,aAAa,CAACN,QAAQ,CAAC;QACjD,MAAMO,SAAS,GAAGP,QAAQ,KAAK,IAAI;QACnC,MAAMQ,KAAK,GAAGD,SAAS,GAAGhD,YAAY,GAAG,CAAC,GAC7B8C,iBAAiB,GAAG9C,YAAY,GAAG,CAAC,GACpCA,YAAY;;QAEzB;QACAkD,UAAU,CAAC,MAAM;UACfR,qBAAqB,CAACR,aAAa,CAAC;QACtC,CAAC,EAAEe,KAAK,CAAC;MACX,CAAC,MAAM;QACL;QACAtC,WAAW,CAAC,KAAK,CAAC;QAClBK,iBAAiB,CAACK,OAAO,GAAG,IAAI;;QAEhC;QACA,IAAIN,YAAY,CAACM,OAAO,EAAE;UACxB,MAAM8B,aAAa,GAAGpC,YAAY,CAACM,OAAO;UAC1CN,YAAY,CAACM,OAAO,GAAG,IAAI;UAC3BJ,WAAW,CAACkC,aAAa,CAAC;QAC5B;MACF;IACF,CAAC;;IAED;IACAD,UAAU,CAAChB,aAAa,EAAE,GAAG,CAAC;EAChC,CAAC,EAAE,EAAE,CAAC;;EAEN;EACA,MAAMa,aAAa,GAAIK,IAAY,IAAc;IAC/C,OAAO,CAAC,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,EAAE,GAAG,CAAC,CAACC,QAAQ,CAACD,IAAI,CAAC;EACtD,CAAC;EAED,MAAME,gBAAgB,GAAG3D,WAAW,CAAC,MAAO4D,WAAmB,IAAK;IAClE,IAAI;MACF9C,YAAY,CAAC,IAAI,CAAC;MAClBI,QAAQ,CAAC,IAAI,CAAC;;MAEd;MACA,MAAM2C,cAAuB,GAAG;QAC9B7B,EAAE,EAAEJ,IAAI,CAACC,GAAG,CAAC,CAAC,CAACC,QAAQ,CAAC,CAAC;QACzBG,OAAO,EAAE2B,WAAW;QACpB1B,MAAM,EAAE,IAAI;QACZC,SAAS,EAAE,IAAIP,IAAI,CAAC;MACtB,CAAC;MAEDhB,WAAW,CAACmB,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAE8B,cAAc,CAAC,CAAC;;MAE9C;MACA,IAAIC,QAAQ;MAEZ,IAAI;QACF,IAAI3C,aAAa,KAAK,eAAe,EAAE;UACrC2C,QAAQ,GAAG,MAAM3D,4BAA4B,CAACyD,WAAW,CAAC;QAC5D,CAAC,MAAM;UACLE,QAAQ,GAAG,MAAM5D,4BAA4B,CAAC0D,WAAW,CAAC;QAC5D;;QAEA;QACA,IAAI,CAACE,QAAQ,IAAI,OAAOA,QAAQ,KAAK,QAAQ,EAAE;UAC7C,MAAM,IAAIC,KAAK,CAAC,yBAAyB,CAAC;QAC5C;;QAEA;QACAzC,WAAW,CAACwC,QAAQ,CAAC;MACvB,CAAC,CAAC,OAAOE,QAAQ,EAAE;QACjBxC,OAAO,CAACP,KAAK,CAAC,YAAY,EAAE+C,QAAQ,CAAC;QACrC9C,QAAQ,CAAC,uEAAuE,CAAC;MACnF;IAEF,CAAC,CAAC,OAAO+C,GAAG,EAAE;MACZzC,OAAO,CAACP,KAAK,CAAC,4BAA4B,EAAEgD,GAAG,CAAC;MAChD/C,QAAQ,CAAC,kDAAkD,CAAC;IAC9D,CAAC,SAAS;MACRJ,YAAY,CAAC,KAAK,CAAC;IACrB;EACF,CAAC,EAAE,CAACK,aAAa,EAAEG,WAAW,CAAC,CAAC;EAEhC,MAAM4C,WAAW,GAAGlE,WAAW,CAAC,MAAOiC,OAAe,IAAK;IACzD,IAAI,CAACA,OAAO,CAACkC,IAAI,CAAC,CAAC,EAAE;;IAErB;IACAjD,QAAQ,CAAC,IAAI,CAAC;;IAEd;IACA,MAAM0C,WAAoB,GAAG;MAC3B5B,EAAE,EAAEJ,IAAI,CAACC,GAAG,CAAC,CAAC,CAACC,QAAQ,CAAC,CAAC;MACzBG,OAAO,EAAEA,OAAO,CAACkC,IAAI,CAAC,CAAC;MACvBjC,MAAM,EAAE,IAAI;MACZC,SAAS,EAAE,IAAIP,IAAI,CAAC;IACtB,CAAC;IACDhB,WAAW,CAACmB,IAAI,IAAI,CAAC,GAAGA,IAAI,EAAE6B,WAAW,CAAC,CAAC;;IAE3C;IACA,MAAME,QAAQ,GAAG,MAAMH,gBAAgB,CAAC1B,OAAO,CAAC;IAEhD,IAAI6B,QAAQ,EAAE;MACZ;MACA,IAAI/C,QAAQ,EAAE;QACZK,YAAY,CAACM,OAAO,GAAGoC,QAAQ;MACjC,CAAC,MAAM;QACL;QACAxC,WAAW,CAACwC,QAAQ,CAAC;MACvB;IACF;EACF,CAAC,EAAE,CAACH,gBAAgB,EAAE5C,QAAQ,EAAEO,WAAW,CAAC,CAAC;EAE7C,MAAM8C,aAAa,GAAGpE,WAAW,CAAC,MAAM;IACtCY,WAAW,CAAC,EAAE,CAAC;IACfM,QAAQ,CAAC,IAAI,CAAC;IACdE,YAAY,CAACM,OAAO,GAAG,IAAI;IAC3BL,iBAAiB,CAACK,OAAO,GAAG,IAAI;EAClC,CAAC,EAAE,EAAE,CAAC;EAEN,OAAO;IACLf,QAAQ;IACRE,SAAS;IACTE,QAAQ;IACRE,KAAK;IACLiD,WAAW;IACX/C,aAAa;IACbiD;EACF,CAAC;AACH,CAAC;AAAC1D,EAAA,CAhMWD,OAAO;EAAA,QAKQL,SAAS;AAAA;AA6LrC,eAAeK,OAAO","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}